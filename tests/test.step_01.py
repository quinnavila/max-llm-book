"""Tests for GPT2Config in puzzles/config.py"""

import sys
from pathlib import Path

sys.path.insert(0, str(Path(__file__).parent.parent))
from steps import step_01 as config_module
import inspect


def test_gpt2_config():
    """Test that GPT2Config has the correct hyperparameter values."""
    config = config_module.GPT2Config()
    print("Running tests for Step 01: Create Model Configuration...\n")
    print("Results:")

    # Test if dataclass is imported from dataclasses
    if "dataclasses" in config_module.__dict__.get("__annotations__", {}) or hasattr(
        config_module, "dataclass"
    ):
        # Check if dataclass is actually imported
        source = inspect.getsource(config_module)
        if "from dataclasses import dataclass" in source:
            print("‚úÖ dataclass is correctly imported from dataclasses")
        else:
            print("‚ùå dataclass is not imported from dataclasses")
    else:
        source = inspect.getsource(config_module)
        if "from dataclasses import dataclass" in source:
            print("‚úÖ dataclass is correctly imported from dataclasses")
        else:
            print("‚ùå dataclass is not imported from dataclasses")

    # Test if GPT2Config has the @dataclass decorator
    if hasattr(config_module.GPT2Config(), "__dataclass_fields__"):
        print("‚úÖ GPT2Config has the @dataclass decorator")
    else:
        print("‚ùå GPT2Config does not have the @dataclass decorator")

    # Test vocab_size
    if config.vocab_size == 50257:
        print("‚úÖ vocab_size is correct: 50257")
    else:
        print(
            f"‚ùå vocab_size is incorrect: expected match with Hugging Face model configuration, got {config.vocab_size}"
        )

    # Test n_positions
    if config.n_positions == 1024:
        print("‚úÖ n_positions is correct: 1024")
    else:
        print(
            f"‚ùå n_positions is incorrect: expected match with Hugging Face model configuration, got {config.n_positions}"
        )

    # Test n_embd
    if config.n_embd == 768:
        print("‚úÖ n_embd is correct: 768")
    else:
        print(
            f"‚ùå n_embd is incorrect: expected match with Hugging Face model configuration, got {config.n_embd}"
        )

    # Test n_layer
    if config.n_layer == 12:
        print("‚úÖ n_layer is correct: 12")
    else:
        print(
            f"‚ùå n_layer is incorrect: expected match with Hugging Face model configuration, got {config.n_layer}"
        )

    # Test n_head
    if config.n_head == 12:
        print("‚úÖ n_head is correct: 12")
    else:
        print(
            f"‚ùå n_head is incorrect: expected match with Hugging Face model configuration, got {config.n_head}"
        )

    # Test n_inner
    if config.n_inner == 3072:
        print("‚úÖ n_inner is correct: 3072")
    else:
        print(
            f"‚ùå n_inner is incorrect: expected match with Hugging Face model configuration, got {config.n_inner}"
        )

    # Test layer_norm_epsilon
    if config.layer_norm_epsilon == 1e-05:
        print("‚úÖ layer_norm_epsilon is correct: 1e-05")
    else:
        print(
            f"‚ùå layer_norm_epsilon is incorrect: expected match with Hugging Face model configuration, got {config.layer_norm_epsilon}"
        )

    # Final summary
    print("\n" + "=" * 60)
    if all(
        [
            "from dataclasses import dataclass" in source,
            hasattr(config, "__dataclass_fields__"),
            config.vocab_size == 50257,
            config.n_positions == 1024,
            config.n_embd == 768,
            config.n_layer == 12,
            config.n_head == 12,
            config.n_inner == 3072,
            config.layer_norm_epsilon == 1e-05,
        ]
    ):
        print("üéâ All checks passed! Your implementation matches the solution.")
        print("=" * 60)
    else:
        print("‚ö†Ô∏è  Some checks failed. Review the hints above and try again.")
        print("=" * 60)


if __name__ == "__main__":
    test_gpt2_config()
